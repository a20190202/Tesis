{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70ed420",
   "metadata": {},
   "source": [
    "# Preprocesamiento III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253227",
   "metadata": {},
   "source": [
    "## 6. Formato YOLOv4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e8511",
   "metadata": {},
   "source": [
    "### 6.1. convert_coco_to_yolov4\n",
    "Converts a COCO JSON annotation file into YOLOv4 format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e246fc",
   "metadata": {},
   "source": [
    "#### i. Convertir al formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b1b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9ab831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_coco_to_yolov4(coco_json_path, output_path):\n",
    "    \"\"\"\n",
    "    Converts a COCO JSON annotation file into YOLOv4 format.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        output_path (str): Directory where YOLOv4 label files will be saved.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Create dictionary for image dimensions\n",
    "    image_info = {img['id']: img for img in coco_data['images']}\n",
    "\n",
    "    # Create dictionary for category mapping\n",
    "    category_mapping = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n",
    "\n",
    "    # Group annotations by image\n",
    "    annotations_by_image = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        annotations_by_image.setdefault(img_id, []).append(ann)\n",
    "\n",
    "    for img_id, annotations in annotations_by_image.items():\n",
    "        img_data = image_info[img_id]\n",
    "        file_name = os.path.splitext(img_data['file_name'])[0] + '.txt'\n",
    "        txt_path = os.path.join(output_path, file_name)\n",
    "\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            for ann in annotations:\n",
    "                cat_id = ann['category_id']\n",
    "                bbox = ann['bbox']  # [x_min, y_min, width, height]\n",
    "                x_center = (bbox[0] + bbox[2] / 2) / img_data['width']\n",
    "                y_center = (bbox[1] + bbox[3] / 2) / img_data['height']\n",
    "                width = bbox[2] / img_data['width']\n",
    "                height = bbox[3] / img_data['height']\n",
    "                class_id = category_mapping[cat_id]\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7ba877",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolov4('merged-dataset/subsets/train.json', 'merged-dataset/subsets/yolo_format/train_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62922f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolov4('merged-dataset/subsets/valid.json', 'merged-dataset/subsets/yolo_format/valid_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolov4('merged-dataset/redim/train.json', 'merged-dataset/redim_yolo/train/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912382c",
   "metadata": {},
   "source": [
    "#### ii. Contar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f4f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_txt_files(input_path):\n",
    "    \"\"\"\n",
    "    Counts the number of .txt files in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of .txt files found.\n",
    "    \"\"\"\n",
    "    count = sum(\n",
    "        1 for file in os.listdir(input_path)\n",
    "        if os.path.isfile(os.path.join(input_path, file)) and file.lower().endswith('.txt')\n",
    "    )\n",
    "    print(f\"Total .txt files in '{input_path}': {count}\")\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c505ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .txt files in 'merged-dataset/redim_yolo/train/labels': 1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_txt_files('merged-dataset/redim_yolo/train/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064d08c",
   "metadata": {},
   "source": [
    "### 6.2. copy_coco_images\n",
    "Copies only the images referenced in the COCO JSON to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c2daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_coco_images(coco_json_path, input_image_path, output_image_path):\n",
    "    \"\"\"\n",
    "    Copies only the images referenced in the COCO JSON to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        input_image_path (str): Directory where original images are located.\n",
    "        output_image_path (str): Directory where referenced images will be copied.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    os.makedirs(output_image_path, exist_ok=True)\n",
    "\n",
    "    image_filenames = {img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "    for file_name in image_filenames:\n",
    "        src_path = os.path.join(input_image_path, file_name)\n",
    "        dst_path = os.path.join(output_image_path, file_name)\n",
    "\n",
    "        # Create destination subdirectories if needed\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"[WARNING] File not found: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_coco_images('merged-dataset/subsets/train.json', 'merged-dataset/images', 'merged-dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf91c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_coco_images('merged-dataset/subsets/valid.json', 'merged-dataset/images', 'merged-dataset/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9e6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c07aa05b",
   "metadata": {},
   "source": [
    "### 6.3 create_yolo_image_list_path_car_models\n",
    "Generates a .txt file listing full image paths from COCO JSON using a base path and category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da536d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_yolo_image_list_path_car_models(base_path, coco_json_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Generates a .txt file listing full image paths from COCO JSON using a base path and category names.\n",
    "\n",
    "    Parameters:\n",
    "        base_path (str): Base path to prepend to each image file name.\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        output_txt_path (str): Path to the output .txt file (including the file name).\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "    category_id_to_name = {\n",
    "        cat['id']: cat['name'].replace(' ', '_') for cat in coco_data['categories']\n",
    "    }\n",
    "\n",
    "    image_to_category = defaultdict(list)\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        if category_id not in image_to_category[image_id]:\n",
    "            image_to_category[image_id].append(category_id)\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as out_file:\n",
    "        for image_id, file_name in image_id_to_filename.items():\n",
    "            if image_id in image_to_category:\n",
    "                first_category_id = image_to_category[image_id][0]\n",
    "                category_name = category_id_to_name.get(first_category_id, 'Unknown')\n",
    "                image_path = f\"{base_path.rstrip('/')}/{category_name}/{file_name}\"\n",
    "                out_file.write(f\"{image_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca99720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53685b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_image_list_path_car_models(\n",
    "    base_path='data/',\n",
    "    coco_json_path='merged-dataset/subsets/valid.json',\n",
    "    output_txt_path='merged-dataset/yolo_format/valid.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81518b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_image_list_path_car_models(\n",
    "    base_path='data/',\n",
    "    coco_json_path='merged-dataset/subsets/train.json',\n",
    "    output_txt_path='merged-dataset/yolo_format/train.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45be0df",
   "metadata": {},
   "source": [
    "### 6.4. display_image_dimensions_with_frequency \n",
    "Loads a COCO JSON and displays total image count, frequency and proportional frequency of each (width, height) dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cee33901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd66173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_dimensions_with_stats(coco_json_path):\n",
    "    \"\"\"\n",
    "    Loads a COCO JSON and displays total image count,\n",
    "    frequency and proportional frequency of each (width, height) dimension.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO-format JSON file.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    dimensions = [(img['width'], img['height']) for img in coco_data.get('images', [])]\n",
    "    total_images = len(dimensions)\n",
    "    dimension_counts = Counter(dimensions)\n",
    "\n",
    "    print(f\"Total number of images: {total_images}\\n\")\n",
    "    print(\"Image dimensions with frequency and proportional frequency:\")\n",
    "    for dim, count in sorted(dimension_counts.items()):\n",
    "        proportion = (count / total_images) * 100\n",
    "        print(f\"{dim}: {count} images ({proportion:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8c0c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 832\n",
      "\n",
      "Image dimensions with frequency and proportional frequency:\n",
      "(640, 640): 237 images (28.49%)\n",
      "(1536, 2048): 2 images (0.24%)\n",
      "(2048, 1536): 1 images (0.12%)\n",
      "(3000, 4000): 472 images (56.73%)\n",
      "(4000, 3000): 113 images (13.58%)\n",
      "(6000, 8000): 7 images (0.84%)\n"
     ]
    }
   ],
   "source": [
    "display_image_dimensions_with_stats('datasets/unified_dataset/_annotations.coco.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41093690",
   "metadata": {},
   "source": [
    "### 6.5. resize_yolo_images_and_labels\n",
    "Reize images and modify its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d95e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd02e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def resize_yolo_images_and_labels(input_path, output_path, target_size=(608, 608)):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    for file in os.listdir(input_path):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_path, file)\n",
    "            label_path = os.path.join(input_path, os.path.splitext(file)[0] + '.txt')\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            h_orig, w_orig = image.shape[:2]\n",
    "\n",
    "            resized_image = cv2.resize(image, (target_w, target_h))\n",
    "            output_image_path = os.path.join(output_path, file)\n",
    "            cv2.imwrite(output_image_path, resized_image)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                output_label_path = os.path.join(output_path, os.path.splitext(file)[0] + '.txt')\n",
    "                with open(label_path, 'r') as f_in, open(output_label_path, 'w') as f_out:\n",
    "                    for line in f_in:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) != 5:\n",
    "                            continue\n",
    "                        cls, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                        # Convert from relative to absolute\n",
    "                        x_abs = x_center * w_orig\n",
    "                        y_abs = y_center * h_orig\n",
    "                        w_abs = width * w_orig\n",
    "                        h_abs = height * h_orig\n",
    "\n",
    "                        # Resize absolute values according to new size\n",
    "                        x_resized = x_abs * (target_w / w_orig)\n",
    "                        y_resized = y_abs * (target_h / h_orig)\n",
    "                        w_resized = w_abs * (target_w / w_orig)\n",
    "                        h_resized = h_abs * (target_h / h_orig)\n",
    "\n",
    "                        # Convert back to relative\n",
    "                        x_new = x_resized / target_w\n",
    "                        y_new = y_resized / target_h\n",
    "                        w_new = w_resized / target_w\n",
    "                        h_new = h_resized / target_h\n",
    "\n",
    "                        f_out.write(f\"{int(cls)} {x_new:.6f} {y_new:.6f} {w_new:.6f} {h_new:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45dd22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_yolo_images_and_labels('merged-dataset/yolo_upload/all', 'merged-dataset/yolo_upload/resized', target_size=(640, 640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff00b1a",
   "metadata": {},
   "source": [
    "### 6.6. save_yolo_bboxes_to_images\n",
    "Save images with bounding boxes drawn from YOLO annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yolo_bboxes_to_images(input_dir, output_dir='output', max_images=None):\n",
    "    \"\"\"\n",
    "    Save images with bounding boxes drawn from YOLO annotations.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing the images and YOLO .txt annotation files.\n",
    "        output_dir (str): Directory to save output images with drawn bounding boxes.\n",
    "        max_images (int, optional): If provided, randomly selects up to this number of images (without repetition).\n",
    "    \"\"\"\n",
    "    from PIL import Image, ImageDraw\n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    if max_images is not None and max_images < len(image_files):\n",
    "        image_files = random.sample(image_files, max_images)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_dir, image_file)\n",
    "        label_path = os.path.join(input_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "        output_path = os.path.join(output_dir, image_file)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"[WARNING] Annotation file not found for image: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        w_img, h_img = image.size\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                _, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                # Convert YOLO normalized format to absolute pixel coordinates\n",
    "                x_center *= w_img\n",
    "                y_center *= h_img\n",
    "                width *= w_img\n",
    "                height *= h_img\n",
    "\n",
    "                x0 = x_center - width / 2\n",
    "                y0 = y_center - height / 2\n",
    "                x1 = x_center + width / 2\n",
    "                y1 = y_center + height / 2\n",
    "\n",
    "                draw.rectangle([x0, y0, x1, y1], outline='red', width=3)\n",
    "\n",
    "        image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5fbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_yolo_bboxes_to_images('merged-dataset/yolo_upload/resized', output_dir='merged-dataset/yolo_upload/resized_bbox', max_images=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39785346",
   "metadata": {},
   "source": [
    "### 6.7. show_yolo_bboxes\n",
    "Displays a single image with its YOLO-format bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c825a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_yolo_bboxes(image_path, annotations_dir):\n",
    "    \"\"\"\n",
    "    Displays a single image with its YOLO-format bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Full path to the image file.\n",
    "        annotations_dir (str): Directory containing YOLO .txt annotations.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"[ERROR] Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    annotation_path = os.path.join(annotations_dir, filename + '.txt')\n",
    "\n",
    "    if not os.path.exists(annotation_path):\n",
    "        print(f\"[WARNING] Annotation file not found for image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    w_img, h_img = image.size\n",
    "\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            _, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "            # Convert to absolute coordinates\n",
    "            x_center *= w_img\n",
    "            y_center *= h_img\n",
    "            width *= w_img\n",
    "            height *= h_img\n",
    "\n",
    "            x0 = x_center - width / 2\n",
    "            y0 = y_center - height / 2\n",
    "            x1 = x_center + width / 2\n",
    "            y1 = y_center + height / 2\n",
    "\n",
    "            draw.rectangle([x0, y0, x1, y1], outline='red', width=3)\n",
    "\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a106acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_bboxes('datasets/unified_dataset/yolo_upload/plate_all_dimensions/20231009_193031.jpg', 'datasets/unified_dataset/yolo_upload/plate_all_dimensions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e9f02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_bboxes('datasets/unified_dataset/yolo_upload/plate/20231009_193031.jpg', 'datasets/unified_dataset/yolo_upload/plate/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888dbcc",
   "metadata": {},
   "source": [
    "### 6.8. copy_images_and_labels_by_category\n",
    "Copies images and their corresponding YOLO annotation .txt files into categorized folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02808e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_images_and_labels_by_category(input_data_path, input_txt_list_path, output_path):\n",
    "    \"\"\"\n",
    "    Copies images and their corresponding YOLO annotation .txt files into categorized folders.\n",
    "\n",
    "    Parameters:\n",
    "        input_data_path (str): Path containing images and YOLO .txt annotations.\n",
    "        input_txt_list_path (str): Path to the .txt file listing relative paths (e.g. data/Brand_Model/image.jpg).\n",
    "        output_path (str): Destination directory to store categorized folders with image + annotation.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    with open(input_txt_list_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for relative_path in lines:\n",
    "        relative_path = relative_path.strip()\n",
    "        if not relative_path or not relative_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        parts = relative_path.split('/')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "\n",
    "        category_name = parts[1]\n",
    "        image_name = parts[-1]\n",
    "        txt_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "\n",
    "        src_image_path = os.path.join(input_data_path, image_name)\n",
    "        src_txt_path = os.path.join(input_data_path, txt_name)\n",
    "\n",
    "        dst_category_path = os.path.join(output_path, category_name)\n",
    "        os.makedirs(dst_category_path, exist_ok=True)\n",
    "\n",
    "        dst_image_path = os.path.join(dst_category_path, image_name)\n",
    "        dst_txt_path = os.path.join(dst_category_path, txt_name)\n",
    "\n",
    "        if os.path.exists(src_image_path):\n",
    "            shutil.copy2(src_image_path, dst_image_path)\n",
    "\n",
    "        if os.path.exists(src_txt_path):\n",
    "            shutil.copy2(src_txt_path, dst_txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f495fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images_and_labels_by_category(\n",
    "    input_data_path='merged-dataset/yolo_upload/resized',\n",
    "    input_txt_list_path='merged-dataset/yolo_format/train.txt',\n",
    "    output_path='merged-dataset/yolo_upload/sorted_by_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e15b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images_and_labels_by_category(\n",
    "    input_data_path='merged-dataset/yolo_upload/resized',\n",
    "    input_txt_list_path='merged-dataset/yolo_format/valid.txt',\n",
    "    output_path='merged-dataset/yolo_upload/sorted_by_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf90fe",
   "metadata": {},
   "source": [
    "### 6.9. list_subfolders_to_txt\n",
    " Writes the names of all subfolders inside input_path to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21928b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_subfolders_to_txt(input_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Writes the names of all subfolders inside input_path to a .txt file.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Directory containing subfolders.\n",
    "        output_txt_path (str): Full path to the output .txt file.\n",
    "    \"\"\"\n",
    "    subfolders = [\n",
    "        name for name in os.listdir(input_path)\n",
    "        if os.path.isdir(os.path.join(input_path, name))\n",
    "    ]\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for folder_name in subfolders:\n",
    "            f.write(f\"{folder_name}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e971af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subfolders_to_txt(\n",
    "    input_path='merged-dataset/yolo_upload/sorted_by_category',\n",
    "    output_txt_path='merged-dataset/yolo_upload/category_list.txt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156544b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd5e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "776bdbef",
   "metadata": {},
   "source": [
    "## 7. Formato FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91943c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756a934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_category_ids_coco(input_json_path, output_json_path):\n",
    "    # Crear carpeta de salida si no existe\n",
    "    output_dir = os.path.dirname(output_json_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Cargar el COCO JSON\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Incrementar category_id en anotaciones\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        annotation['category_id'] += 1\n",
    "\n",
    "    # Incrementar id en categories (opcional, solo si quieres también ajustar categorías)\n",
    "    for category in coco_data.get('categories', []):\n",
    "        category['id'] += 1\n",
    "\n",
    "    # Guardar el nuevo COCO JSON\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(coco_data, f)\n",
    "\n",
    "    print(f\"[INFO] Nuevo COCO JSON guardado en: {output_json_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e0051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Nuevo COCO JSON guardado en: merged-dataset/redim_faster/train.json\n"
     ]
    }
   ],
   "source": [
    "increment_category_ids_coco(\"merged-dataset/redim/train.json\", \"merged-dataset/redim_faster/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c93809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Nuevo COCO JSON guardado en: merged-dataset/redim_faster/valid.json\n"
     ]
    }
   ],
   "source": [
    "increment_category_ids_coco(\"merged-dataset/redim/valid.json\", \"merged-dataset/redim_faster/valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e62ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Nuevo COCO JSON guardado en: merged-dataset/redim_faster/test.json\n"
     ]
    }
   ],
   "source": [
    "increment_category_ids_coco(\"merged-dataset/redim/test.json\", \"merged-dataset/redim_faster/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb8d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Nuevo COCO JSON guardado en: merged-dataset/redim_faster/train_augmented.json\n"
     ]
    }
   ],
   "source": [
    "increment_category_ids_coco(\"merged-dataset/redim/train_augmented.json\", \"merged-dataset/redim_faster/train_augmented.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
