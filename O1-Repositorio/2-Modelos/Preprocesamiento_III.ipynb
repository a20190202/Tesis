{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70ed420",
   "metadata": {},
   "source": [
    "# Preprocesamiento III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253227",
   "metadata": {},
   "source": [
    "# 6. Formato YOLOv4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e8511",
   "metadata": {},
   "source": [
    "### 6.1. convert_coco_to_yolov4\n",
    "Converts a COCO JSON annotation file into YOLOv4 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b1b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9ab831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_coco_to_yolov4(coco_json_path, output_path):\n",
    "    \"\"\"\n",
    "    Converts a COCO JSON annotation file into YOLOv4 format.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        output_path (str): Directory where YOLOv4 label files will be saved.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Create dictionary for image dimensions\n",
    "    image_info = {img['id']: img for img in coco_data['images']}\n",
    "\n",
    "    # Create dictionary for category mapping\n",
    "    category_mapping = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n",
    "\n",
    "    # Group annotations by image\n",
    "    annotations_by_image = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        annotations_by_image.setdefault(img_id, []).append(ann)\n",
    "\n",
    "    for img_id, annotations in annotations_by_image.items():\n",
    "        img_data = image_info[img_id]\n",
    "        file_name = os.path.splitext(img_data['file_name'])[0] + '.txt'\n",
    "        txt_path = os.path.join(output_path, file_name)\n",
    "\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            for ann in annotations:\n",
    "                cat_id = ann['category_id']\n",
    "                bbox = ann['bbox']  # [x_min, y_min, width, height]\n",
    "                x_center = (bbox[0] + bbox[2] / 2) / img_data['width']\n",
    "                y_center = (bbox[1] + bbox[3] / 2) / img_data['height']\n",
    "                width = bbox[2] / img_data['width']\n",
    "                height = bbox[3] / img_data['height']\n",
    "                class_id = category_mapping[cat_id]\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7ba877",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolov4('merged-dataset/subsets/train.json', 'merged-dataset/subsets/yolo_format/train_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62922f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_to_yolov4('merged-dataset/subsets/valid.json', 'merged-dataset/subsets/yolo_format/valid_annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064d08c",
   "metadata": {},
   "source": [
    "### 6.2. copy_coco_images\n",
    "Copies only the images referenced in the COCO JSON to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c2daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_coco_images(coco_json_path, input_image_path, output_image_path):\n",
    "    \"\"\"\n",
    "    Copies only the images referenced in the COCO JSON to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        input_image_path (str): Directory where original images are located.\n",
    "        output_image_path (str): Directory where referenced images will be copied.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    os.makedirs(output_image_path, exist_ok=True)\n",
    "\n",
    "    image_filenames = {img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "    for file_name in image_filenames:\n",
    "        src_path = os.path.join(input_image_path, file_name)\n",
    "        dst_path = os.path.join(output_image_path, file_name)\n",
    "\n",
    "        # Create destination subdirectories if needed\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"[WARNING] File not found: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_coco_images('merged-dataset/subsets/train.json', 'merged-dataset/images', 'merged-dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf91c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_coco_images('merged-dataset/subsets/valid.json', 'merged-dataset/images', 'merged-dataset/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9e6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c07aa05b",
   "metadata": {},
   "source": [
    "### 6.3 create_yolo_image_list_path_car_models\n",
    "Generates a .txt file listing full image paths from COCO JSON using a base path and category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da536d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_yolo_image_list_path_car_models(base_path, coco_json_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Generates a .txt file listing full image paths from COCO JSON using a base path and category names.\n",
    "\n",
    "    Parameters:\n",
    "        base_path (str): Base path to prepend to each image file name.\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        output_txt_path (str): Path to the output .txt file (including the file name).\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "\n",
    "    category_id_to_name = {\n",
    "        cat['id']: cat['name'].replace(' ', '_') for cat in coco_data['categories']\n",
    "    }\n",
    "\n",
    "    image_to_category = defaultdict(list)\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        if category_id not in image_to_category[image_id]:\n",
    "            image_to_category[image_id].append(category_id)\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as out_file:\n",
    "        for image_id, file_name in image_id_to_filename.items():\n",
    "            if image_id in image_to_category:\n",
    "                first_category_id = image_to_category[image_id][0]\n",
    "                category_name = category_id_to_name.get(first_category_id, 'Unknown')\n",
    "                image_path = f\"{base_path.rstrip('/')}/{category_name}/{file_name}\"\n",
    "                out_file.write(f\"{image_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca99720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53685b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_image_list_path_car_models(\n",
    "    base_path='data/',\n",
    "    coco_json_path='merged-dataset/subsets/valid.json',\n",
    "    output_txt_path='merged-dataset/yolo_format/valid.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81518b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_image_list_path_car_models(\n",
    "    base_path='data/',\n",
    "    coco_json_path='merged-dataset/subsets/train.json',\n",
    "    output_txt_path='merged-dataset/yolo_format/train.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45be0df",
   "metadata": {},
   "source": [
    "### 6.4. display_image_dimensions_with_frequency \n",
    "Loads a COCO JSON and displays total image count, frequency and proportional frequency of each (width, height) dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cee33901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd66173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_dimensions_with_stats(coco_json_path):\n",
    "    \"\"\"\n",
    "    Loads a COCO JSON and displays total image count,\n",
    "    frequency and proportional frequency of each (width, height) dimension.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO-format JSON file.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    dimensions = [(img['width'], img['height']) for img in coco_data.get('images', [])]\n",
    "    total_images = len(dimensions)\n",
    "    dimension_counts = Counter(dimensions)\n",
    "\n",
    "    print(f\"Total number of images: {total_images}\\n\")\n",
    "    print(\"Image dimensions with frequency and proportional frequency:\")\n",
    "    for dim, count in sorted(dimension_counts.items()):\n",
    "        proportion = (count / total_images) * 100\n",
    "        print(f\"{dim}: {count} images ({proportion:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8c0c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 832\n",
      "\n",
      "Image dimensions with frequency and proportional frequency:\n",
      "(640, 640): 237 images (28.49%)\n",
      "(1536, 2048): 2 images (0.24%)\n",
      "(2048, 1536): 1 images (0.12%)\n",
      "(3000, 4000): 472 images (56.73%)\n",
      "(4000, 3000): 113 images (13.58%)\n",
      "(6000, 8000): 7 images (0.84%)\n"
     ]
    }
   ],
   "source": [
    "display_image_dimensions_with_stats('datasets/unified_dataset/_annotations.coco.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41093690",
   "metadata": {},
   "source": [
    "### 6.5. resize_yolo_images_and_labels\n",
    "Reize images and modify its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d95e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd02e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def resize_yolo_images_and_labels(input_path, output_path, target_size=(608, 608)):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    target_w, target_h = target_size\n",
    "\n",
    "    for file in os.listdir(input_path):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_path, file)\n",
    "            label_path = os.path.join(input_path, os.path.splitext(file)[0] + '.txt')\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            h_orig, w_orig = image.shape[:2]\n",
    "\n",
    "            resized_image = cv2.resize(image, (target_w, target_h))\n",
    "            output_image_path = os.path.join(output_path, file)\n",
    "            cv2.imwrite(output_image_path, resized_image)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                output_label_path = os.path.join(output_path, os.path.splitext(file)[0] + '.txt')\n",
    "                with open(label_path, 'r') as f_in, open(output_label_path, 'w') as f_out:\n",
    "                    for line in f_in:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) != 5:\n",
    "                            continue\n",
    "                        cls, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                        # Convert from relative to absolute\n",
    "                        x_abs = x_center * w_orig\n",
    "                        y_abs = y_center * h_orig\n",
    "                        w_abs = width * w_orig\n",
    "                        h_abs = height * h_orig\n",
    "\n",
    "                        # Resize absolute values according to new size\n",
    "                        x_resized = x_abs * (target_w / w_orig)\n",
    "                        y_resized = y_abs * (target_h / h_orig)\n",
    "                        w_resized = w_abs * (target_w / w_orig)\n",
    "                        h_resized = h_abs * (target_h / h_orig)\n",
    "\n",
    "                        # Convert back to relative\n",
    "                        x_new = x_resized / target_w\n",
    "                        y_new = y_resized / target_h\n",
    "                        w_new = w_resized / target_w\n",
    "                        h_new = h_resized / target_h\n",
    "\n",
    "                        f_out.write(f\"{int(cls)} {x_new:.6f} {y_new:.6f} {w_new:.6f} {h_new:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45dd22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_yolo_images_and_labels('merged-dataset/yolo_upload/all', 'merged-dataset/yolo_upload/resized', target_size=(640, 640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff00b1a",
   "metadata": {},
   "source": [
    "### 6.6. save_yolo_bboxes_to_images\n",
    "Save images with bounding boxes drawn from YOLO annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yolo_bboxes_to_images(input_dir, output_dir='output', max_images=None):\n",
    "    \"\"\"\n",
    "    Save images with bounding boxes drawn from YOLO annotations.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing the images and YOLO .txt annotation files.\n",
    "        output_dir (str): Directory to save output images with drawn bounding boxes.\n",
    "        max_images (int, optional): If provided, randomly selects up to this number of images (without repetition).\n",
    "    \"\"\"\n",
    "    from PIL import Image, ImageDraw\n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    if max_images is not None and max_images < len(image_files):\n",
    "        image_files = random.sample(image_files, max_images)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(input_dir, image_file)\n",
    "        label_path = os.path.join(input_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "        output_path = os.path.join(output_dir, image_file)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"[WARNING] Annotation file not found for image: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        w_img, h_img = image.size\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                _, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                # Convert YOLO normalized format to absolute pixel coordinates\n",
    "                x_center *= w_img\n",
    "                y_center *= h_img\n",
    "                width *= w_img\n",
    "                height *= h_img\n",
    "\n",
    "                x0 = x_center - width / 2\n",
    "                y0 = y_center - height / 2\n",
    "                x1 = x_center + width / 2\n",
    "                y1 = y_center + height / 2\n",
    "\n",
    "                draw.rectangle([x0, y0, x1, y1], outline='red', width=3)\n",
    "\n",
    "        image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5fbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_yolo_bboxes_to_images('merged-dataset/yolo_upload/resized', output_dir='merged-dataset/yolo_upload/resized_bbox', max_images=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39785346",
   "metadata": {},
   "source": [
    "### 6.7. show_yolo_bboxes\n",
    "Displays a single image with its YOLO-format bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c825a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_yolo_bboxes(image_path, annotations_dir):\n",
    "    \"\"\"\n",
    "    Displays a single image with its YOLO-format bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Full path to the image file.\n",
    "        annotations_dir (str): Directory containing YOLO .txt annotations.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"[ERROR] Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    annotation_path = os.path.join(annotations_dir, filename + '.txt')\n",
    "\n",
    "    if not os.path.exists(annotation_path):\n",
    "        print(f\"[WARNING] Annotation file not found for image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    w_img, h_img = image.size\n",
    "\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            _, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "            # Convert to absolute coordinates\n",
    "            x_center *= w_img\n",
    "            y_center *= h_img\n",
    "            width *= w_img\n",
    "            height *= h_img\n",
    "\n",
    "            x0 = x_center - width / 2\n",
    "            y0 = y_center - height / 2\n",
    "            x1 = x_center + width / 2\n",
    "            y1 = y_center + height / 2\n",
    "\n",
    "            draw.rectangle([x0, y0, x1, y1], outline='red', width=3)\n",
    "\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a106acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_bboxes('datasets/unified_dataset/yolo_upload/plate_all_dimensions/20231009_193031.jpg', 'datasets/unified_dataset/yolo_upload/plate_all_dimensions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e9f02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_bboxes('datasets/unified_dataset/yolo_upload/plate/20231009_193031.jpg', 'datasets/unified_dataset/yolo_upload/plate/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888dbcc",
   "metadata": {},
   "source": [
    "### 6.8. copy_images_and_labels_by_category\n",
    "Copies images and their corresponding YOLO annotation .txt files into categorized folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02808e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_images_and_labels_by_category(input_data_path, input_txt_list_path, output_path):\n",
    "    \"\"\"\n",
    "    Copies images and their corresponding YOLO annotation .txt files into categorized folders.\n",
    "\n",
    "    Parameters:\n",
    "        input_data_path (str): Path containing images and YOLO .txt annotations.\n",
    "        input_txt_list_path (str): Path to the .txt file listing relative paths (e.g. data/Brand_Model/image.jpg).\n",
    "        output_path (str): Destination directory to store categorized folders with image + annotation.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    with open(input_txt_list_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for relative_path in lines:\n",
    "        relative_path = relative_path.strip()\n",
    "        if not relative_path or not relative_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        parts = relative_path.split('/')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "\n",
    "        category_name = parts[1]\n",
    "        image_name = parts[-1]\n",
    "        txt_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "\n",
    "        src_image_path = os.path.join(input_data_path, image_name)\n",
    "        src_txt_path = os.path.join(input_data_path, txt_name)\n",
    "\n",
    "        dst_category_path = os.path.join(output_path, category_name)\n",
    "        os.makedirs(dst_category_path, exist_ok=True)\n",
    "\n",
    "        dst_image_path = os.path.join(dst_category_path, image_name)\n",
    "        dst_txt_path = os.path.join(dst_category_path, txt_name)\n",
    "\n",
    "        if os.path.exists(src_image_path):\n",
    "            shutil.copy2(src_image_path, dst_image_path)\n",
    "\n",
    "        if os.path.exists(src_txt_path):\n",
    "            shutil.copy2(src_txt_path, dst_txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f495fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images_and_labels_by_category(\n",
    "    input_data_path='merged-dataset/yolo_upload/resized',\n",
    "    input_txt_list_path='merged-dataset/yolo_format/train.txt',\n",
    "    output_path='merged-dataset/yolo_upload/sorted_by_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e15b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images_and_labels_by_category(\n",
    "    input_data_path='merged-dataset/yolo_upload/resized',\n",
    "    input_txt_list_path='merged-dataset/yolo_format/valid.txt',\n",
    "    output_path='merged-dataset/yolo_upload/sorted_by_category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf90fe",
   "metadata": {},
   "source": [
    "### 6.9. list_subfolders_to_txt\n",
    " Writes the names of all subfolders inside input_path to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21928b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_subfolders_to_txt(input_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Writes the names of all subfolders inside input_path to a .txt file.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Directory containing subfolders.\n",
    "        output_txt_path (str): Full path to the output .txt file.\n",
    "    \"\"\"\n",
    "    subfolders = [\n",
    "        name for name in os.listdir(input_path)\n",
    "        if os.path.isdir(os.path.join(input_path, name))\n",
    "    ]\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for folder_name in subfolders:\n",
    "            f.write(f\"{folder_name}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e971af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subfolders_to_txt(\n",
    "    input_path='merged-dataset/yolo_upload/sorted_by_category',\n",
    "    output_txt_path='merged-dataset/yolo_upload/category_list.txt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0acf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d92e417b",
   "metadata": {},
   "source": [
    "## 7. Verificacion de Extensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebc528",
   "metadata": {},
   "source": [
    "### 7.1. get_unique_image_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9d0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_unique_image_extensions(coco_json_path):\n",
    "    \"\"\"\n",
    "    Reads a COCO-format JSON file and prints the unique image file extensions.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON annotation file.\n",
    "    \"\"\"\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    extensions = set()\n",
    "    for image in coco_data.get(\"images\", []):\n",
    "        file_name = image.get(\"file_name\", \"\")\n",
    "        _, ext = os.path.splitext(file_name)\n",
    "        if ext:\n",
    "            extensions.add(ext.lower())\n",
    "\n",
    "    print(\"Unique image file extensions found in the dataset:\")\n",
    "    for ext in sorted(extensions):\n",
    "        print(ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918ba4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique image file extensions found in the dataset:\n",
      ".gif\n",
      ".jpeg\n",
      ".jpg\n",
      ".png\n",
      ".webp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_24480\\3017727092.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  get_unique_image_extensions('merged-dataset\\merged_annotations.json')\n"
     ]
    }
   ],
   "source": [
    "get_unique_image_extensions('merged-dataset\\merged_annotations.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2c649",
   "metadata": {},
   "source": [
    "### 7.2. show_non_jpg_png_images_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db1dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def show_non_jpg_png_images_with_categories(coco_json_path):\n",
    "    \"\"\"\n",
    "    Reads a COCO-format JSON file and prints how many images are not in JPG or PNG format,\n",
    "    along with their file names and associated categories.\n",
    "\n",
    "    Parameters:\n",
    "        coco_json_path (str): Path to the COCO JSON annotation file.\n",
    "    \"\"\"\n",
    "    allowed_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    non_compliant_info = {}\n",
    "\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Map image_id to file_name\n",
    "    image_id_to_filename = {\n",
    "        img['id']: img['file_name'] for img in coco.get('images', [])\n",
    "    }\n",
    "\n",
    "    # Map category_id to category name\n",
    "    category_id_to_name = {\n",
    "        cat['id']: cat['name'] for cat in coco.get('categories', [])\n",
    "    }\n",
    "\n",
    "    # Map image_id to list of category_ids\n",
    "    image_id_to_categories = defaultdict(set)\n",
    "    for ann in coco.get('annotations', []):\n",
    "        image_id_to_categories[ann['image_id']].add(ann['category_id'])\n",
    "\n",
    "    # Identify non-compliant images and collect category names\n",
    "    for image_id, file_name in image_id_to_filename.items():\n",
    "        _, ext = os.path.splitext(file_name)\n",
    "        if ext.lower() not in allowed_extensions:\n",
    "            category_names = [category_id_to_name[cid] for cid in image_id_to_categories[image_id]]\n",
    "            non_compliant_info[file_name] = category_names\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Total non-JPG/PNG images: {len(non_compliant_info)}\")\n",
    "    for file_name, categories in non_compliant_info.items():\n",
    "        print(f\"- {file_name}: Categories: {categories}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc750d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-JPG/PNG images: 38\n",
      "- 12.Changan-CS35PLUS-Promo-image.webp: Categories: ['Changan CS35']\n",
      "- 10.changan-cs55-plus-exterior_3.webp: Categories: ['Changan CS55']\n",
      "- 15.changan-cs55-plus-exterior_7.webp: Categories: ['Changan CS55']\n",
      "- 24.RT_PU_db58f70d1fc343aaa1e661ff949f9022.webp: Categories: ['Changan New Van']\n",
      "- 19.NAZ_68b4bedce475447db2b38a7327740261.webp: Categories: ['Chevrolet Camaro']\n",
      "- 12.Chevrolet-Spark_74-scaled.webp: Categories: ['Chevrolet Spark']\n",
      "- 34.glory-500.webp: Categories: ['Glory 500']\n",
      "- 19.2024-Hyundai-Accent.webp: Categories: ['Hyundai Accent']\n",
      "- 28.RT_V_b1e2db279b684f4e8cc4329ee098ae3a.webp: Categories: ['Hyundai Creta']\n",
      "- 29.Hyundai-Creta-Ultimate-0960-1.webp: Categories: ['Hyundai Creta']\n",
      "- 8.1FLP4574-e1680206815844.webp: Categories: ['Hyundai Creta']\n",
      "- 12.DSC_8221-scaled.jpg.webp: Categories: ['Hyundai Santa Fe']\n",
      "- 24.Hyundai-Tucson-2025.webp: Categories: ['Hyundai Tucson']\n",
      "- 12.Hyundai-Veloster-2018-01.jpeg.webp: Categories: ['Hyundai Veloster']\n",
      "- 20.1Dos.influencias.jpg.webp: Categories: ['Hyundai Veloster']\n",
      "- 22.Hyundai-Veloster-2018-05.jpeg.webp: Categories: ['Hyundai Veloster']\n",
      "- 24.hyundai-veloster-5.gif: Categories: ['Hyundai Veloster']\n",
      "- 31.principal_Mesa-de-trabajo-1.webp: Categories: ['JAC T8']\n",
      "- 26.NAZ_7c1d437a26f74f20a0118233290f26d8.webp: Categories: ['Kia Niro']\n",
      "- 31.NPAZ_973a414427ff478f90719214f0c0e09c.webp: Categories: ['Kia Niro']\n",
      "- 28.NAZ_0dde1e51f96943cca7f67bc4fb68384c.webp: Categories: ['Kia Sorento']\n",
      "- 29.NAZ_f5e7196c6aaa45638d56972439f6e238.webp: Categories: ['Kia Sportage']\n",
      "- 27.NISSAN-KICKS-PLAY-2025-003.jpg.webp: Categories: ['Nissan Kicks']\n",
      "- 16.NAZ_d14f0a4c67884a01b4c343dc3430e408.webp: Categories: ['Nissan Sentra']\n",
      "- 14.RT_V_06a4c33100714be1af0e8328f7645596.webp: Categories: ['Nissan Versa']\n",
      "- 26.NAZ_b7841f6b3faf436a911863ed7e390f07.webp: Categories: ['Suzuki Jimny']\n",
      "- 26.suzuki-vitara-facelift-2024-3.webp: Categories: ['Suzuki Vitara']\n",
      "- 1.2025_Toyota_4Runner_Trailhunter_Everest_005-2048x1366-1.webp: Categories: ['Toyota 4Runner']\n",
      "- 16.2025-Toyota-4Runner-Rendering-7-2048x1226-1.webp: Categories: ['Toyota 4Runner']\n",
      "- 29.2025-Toyota-4Runner-Rendering-23-2048x1317-1.webp: Categories: ['Toyota 4Runner']\n",
      "- 3.2025_Toyota_4Runner_Trailhunter_Everest_037-1-jpg.webp: Categories: ['Toyota 4Runner']\n",
      "- 5.2025_Toyota_4Runner_TRDPro_Mudbath_017-2048x1366-1.webp: Categories: ['Toyota 4Runner']\n",
      "- 9.66187f84dae80_nueva-toyota-4runner-2025-este-es-su-costo-y-precio-de-lanzamiento-1024x576.jpg.webp: Categories: ['Toyota 4Runner']\n",
      "- 17.NAZ_4719892dab3e48089f00454e69a0a555.webp: Categories: ['Toyota Corolla']\n",
      "- 18.RT_V_1ba953e0678a4be3a8f46b811f11cd06.webp: Categories: ['Toyota Corolla Cross']\n",
      "- 29.NPAZ_72c81249250a4095bab08e218ca141de.webp: Categories: ['Toyota Corolla Cross']\n",
      "- 10.toyota-land-rover-cruiser-first-editon-reunion-alemania-2-1280x1018.webp: Categories: ['Toyota Land Cruiser']\n",
      "- 31.Portada-5.gif: Categories: ['Toyota Land Cruiser']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_24480\\2074768168.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  show_non_jpg_png_images_with_categories('merged-dataset\\merged_annotations.json')\n"
     ]
    }
   ],
   "source": [
    "show_non_jpg_png_images_with_categories('merged-dataset\\merged_annotations.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91c71a",
   "metadata": {},
   "source": [
    "### 7.3. convert_to_jpg_overwrite(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2acc6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def convert_to_jpg_overwrite(input_path):\n",
    "    \"\"\"\n",
    "    Recursively converts .gif and .webp images to .jpg in a given directory and overwrites them.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Root directory containing folders with images.\n",
    "    \"\"\"\n",
    "    supported_extensions = {'.gif', '.webp'}\n",
    "\n",
    "    for root, _, files in os.walk(input_path):\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            if ext in supported_extensions:\n",
    "                original_path = os.path.join(root, file)\n",
    "                new_path = os.path.splitext(original_path)[0] + '.jpg'\n",
    "\n",
    "                try:\n",
    "                    with Image.open(original_path) as img:\n",
    "                        rgb_img = img.convert('RGB')  # Ensure compatible format\n",
    "                        rgb_img.save(new_path, 'JPEG')\n",
    "                    os.remove(original_path)\n",
    "                    print(f\"Converted and replaced: {original_path} -> {new_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to convert {original_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90912a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted and replaced: merged-dataset/train\\10.toyota-land-rover-cruiser-first-editon-reunion-alemania-2-1280x1018.webp -> merged-dataset/train\\10.toyota-land-rover-cruiser-first-editon-reunion-alemania-2-1280x1018.jpg\n",
      "Converted and replaced: merged-dataset/train\\12.Changan-CS35PLUS-Promo-image.webp -> merged-dataset/train\\12.Changan-CS35PLUS-Promo-image.jpg\n",
      "Converted and replaced: merged-dataset/train\\12.Chevrolet-Spark_74-scaled.webp -> merged-dataset/train\\12.Chevrolet-Spark_74-scaled.jpg\n",
      "Converted and replaced: merged-dataset/train\\12.DSC_8221-scaled.jpg.webp -> merged-dataset/train\\12.DSC_8221-scaled.jpg.jpg\n",
      "Converted and replaced: merged-dataset/train\\12.Hyundai-Veloster-2018-01.jpeg.webp -> merged-dataset/train\\12.Hyundai-Veloster-2018-01.jpeg.jpg\n",
      "Converted and replaced: merged-dataset/train\\14.RT_V_06a4c33100714be1af0e8328f7645596.webp -> merged-dataset/train\\14.RT_V_06a4c33100714be1af0e8328f7645596.jpg\n",
      "Converted and replaced: merged-dataset/train\\15.changan-cs55-plus-exterior_7.webp -> merged-dataset/train\\15.changan-cs55-plus-exterior_7.jpg\n",
      "Converted and replaced: merged-dataset/train\\16.NAZ_d14f0a4c67884a01b4c343dc3430e408.webp -> merged-dataset/train\\16.NAZ_d14f0a4c67884a01b4c343dc3430e408.jpg\n",
      "Converted and replaced: merged-dataset/train\\17.NAZ_4719892dab3e48089f00454e69a0a555.webp -> merged-dataset/train\\17.NAZ_4719892dab3e48089f00454e69a0a555.jpg\n",
      "Converted and replaced: merged-dataset/train\\18.RT_V_1ba953e0678a4be3a8f46b811f11cd06.webp -> merged-dataset/train\\18.RT_V_1ba953e0678a4be3a8f46b811f11cd06.jpg\n",
      "Converted and replaced: merged-dataset/train\\19.2024-Hyundai-Accent.webp -> merged-dataset/train\\19.2024-Hyundai-Accent.jpg\n",
      "Converted and replaced: merged-dataset/train\\19.NAZ_68b4bedce475447db2b38a7327740261.webp -> merged-dataset/train\\19.NAZ_68b4bedce475447db2b38a7327740261.jpg\n",
      "Converted and replaced: merged-dataset/train\\20.1Dos.influencias.jpg.webp -> merged-dataset/train\\20.1Dos.influencias.jpg.jpg\n",
      "Converted and replaced: merged-dataset/train\\22.Hyundai-Veloster-2018-05.jpeg.webp -> merged-dataset/train\\22.Hyundai-Veloster-2018-05.jpeg.jpg\n",
      "Converted and replaced: merged-dataset/train\\24.Hyundai-Tucson-2025.webp -> merged-dataset/train\\24.Hyundai-Tucson-2025.jpg\n",
      "Converted and replaced: merged-dataset/train\\24.hyundai-veloster-5.gif -> merged-dataset/train\\24.hyundai-veloster-5.jpg\n",
      "Converted and replaced: merged-dataset/train\\24.RT_PU_db58f70d1fc343aaa1e661ff949f9022.webp -> merged-dataset/train\\24.RT_PU_db58f70d1fc343aaa1e661ff949f9022.jpg\n",
      "Converted and replaced: merged-dataset/train\\26.NAZ_7c1d437a26f74f20a0118233290f26d8.webp -> merged-dataset/train\\26.NAZ_7c1d437a26f74f20a0118233290f26d8.jpg\n",
      "Converted and replaced: merged-dataset/train\\26.NAZ_b7841f6b3faf436a911863ed7e390f07.webp -> merged-dataset/train\\26.NAZ_b7841f6b3faf436a911863ed7e390f07.jpg\n",
      "Converted and replaced: merged-dataset/train\\26.suzuki-vitara-facelift-2024-3.webp -> merged-dataset/train\\26.suzuki-vitara-facelift-2024-3.jpg\n",
      "Converted and replaced: merged-dataset/train\\27.NISSAN-KICKS-PLAY-2025-003.jpg.webp -> merged-dataset/train\\27.NISSAN-KICKS-PLAY-2025-003.jpg.jpg\n",
      "Converted and replaced: merged-dataset/train\\28.NAZ_0dde1e51f96943cca7f67bc4fb68384c.webp -> merged-dataset/train\\28.NAZ_0dde1e51f96943cca7f67bc4fb68384c.jpg\n",
      "Converted and replaced: merged-dataset/train\\28.RT_V_b1e2db279b684f4e8cc4329ee098ae3a.webp -> merged-dataset/train\\28.RT_V_b1e2db279b684f4e8cc4329ee098ae3a.jpg\n",
      "Converted and replaced: merged-dataset/train\\29.2025-Toyota-4Runner-Rendering-23-2048x1317-1.webp -> merged-dataset/train\\29.2025-Toyota-4Runner-Rendering-23-2048x1317-1.jpg\n",
      "Converted and replaced: merged-dataset/train\\29.Hyundai-Creta-Ultimate-0960-1.webp -> merged-dataset/train\\29.Hyundai-Creta-Ultimate-0960-1.jpg\n",
      "Converted and replaced: merged-dataset/train\\29.NAZ_f5e7196c6aaa45638d56972439f6e238.webp -> merged-dataset/train\\29.NAZ_f5e7196c6aaa45638d56972439f6e238.jpg\n",
      "Converted and replaced: merged-dataset/train\\29.NPAZ_72c81249250a4095bab08e218ca141de.webp -> merged-dataset/train\\29.NPAZ_72c81249250a4095bab08e218ca141de.jpg\n",
      "Converted and replaced: merged-dataset/train\\31.NPAZ_973a414427ff478f90719214f0c0e09c.webp -> merged-dataset/train\\31.NPAZ_973a414427ff478f90719214f0c0e09c.jpg\n",
      "Converted and replaced: merged-dataset/train\\31.Portada-5.gif -> merged-dataset/train\\31.Portada-5.jpg\n",
      "Converted and replaced: merged-dataset/train\\31.principal_Mesa-de-trabajo-1.webp -> merged-dataset/train\\31.principal_Mesa-de-trabajo-1.jpg\n",
      "Converted and replaced: merged-dataset/train\\34.glory-500.webp -> merged-dataset/train\\34.glory-500.jpg\n",
      "Converted and replaced: merged-dataset/train\\5.2025_Toyota_4Runner_TRDPro_Mudbath_017-2048x1366-1.webp -> merged-dataset/train\\5.2025_Toyota_4Runner_TRDPro_Mudbath_017-2048x1366-1.jpg\n",
      "Converted and replaced: merged-dataset/train\\8.1FLP4574-e1680206815844.webp -> merged-dataset/train\\8.1FLP4574-e1680206815844.jpg\n"
     ]
    }
   ],
   "source": [
    "convert_to_jpg_overwrite(\"merged-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60b076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted and replaced: merged-dataset/valid\\10.changan-cs55-plus-exterior_3.webp -> merged-dataset/valid\\10.changan-cs55-plus-exterior_3.jpg\n",
      "Converted and replaced: merged-dataset/valid\\3.2025_Toyota_4Runner_Trailhunter_Everest_037-1-jpg.webp -> merged-dataset/valid\\3.2025_Toyota_4Runner_Trailhunter_Everest_037-1-jpg.jpg\n",
      "Converted and replaced: merged-dataset/valid\\9.66187f84dae80_nueva-toyota-4runner-2025-este-es-su-costo-y-precio-de-lanzamiento-1024x576.jpg.webp -> merged-dataset/valid\\9.66187f84dae80_nueva-toyota-4runner-2025-este-es-su-costo-y-precio-de-lanzamiento-1024x576.jpg.jpg\n"
     ]
    }
   ],
   "source": [
    "convert_to_jpg_overwrite(\"merged-dataset/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156544b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd5e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
