{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf99e006",
   "metadata": {},
   "source": [
    "# 1. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cad1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb635f",
   "metadata": {},
   "source": [
    "## 1.1 Version 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c068a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "Augmenting images: 100%|██████████| 1238/1238 [02:22<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Paths\n",
    "dataset_path = Path(\"datasets/unified_dataset\")\n",
    "aug_dataset_path = Path(\"datasets/unified_dataset_data_augmentation\")\n",
    "aug_images_path = aug_dataset_path / \"images\"\n",
    "aug_images_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load original annotations\n",
    "with open(dataset_path / \"_annotations.coco.json\", 'r') as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# Albumentations pipeline\n",
    "transform = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.9),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "    A.MotionBlur(blur_limit=3, p=0.3)\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "# Prepare new data\n",
    "new_images = []\n",
    "new_annotations = []\n",
    "new_image_id = max(img['id'] for img in coco['images']) + 1\n",
    "new_annotation_id = max(ann['id'] for ann in coco['annotations']) + 1\n",
    "\n",
    "image_id_to_anns = {}\n",
    "for ann in coco['annotations']:\n",
    "    image_id_to_anns.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "# Process each image\n",
    "for img_info in tqdm(coco['images'], desc=\"Augmenting images\"):\n",
    "    img_path = dataset_path / img_info['file_name']\n",
    "    image = cv2.imread(str(img_path))\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    anns = image_id_to_anns.get(img_info['id'], [])\n",
    "    bboxes = [ann['bbox'] for ann in anns]\n",
    "    category_ids = [ann['category_id'] for ann in anns]\n",
    "\n",
    "    if not bboxes:\n",
    "        continue\n",
    "\n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "\n",
    "    # Save new image\n",
    "    new_file_name = f\"aug_{img_info['file_name']}\"\n",
    "    cv2.imwrite(str(aug_images_path / new_file_name), transformed['image'])\n",
    "\n",
    "    # Add new image entry\n",
    "    new_images.append({\n",
    "        \"id\": new_image_id,\n",
    "        \"file_name\": f\"images/{new_file_name}\",\n",
    "        \"width\": img_info['width'],\n",
    "        \"height\": img_info['height']\n",
    "    })\n",
    "\n",
    "    # Add new annotation entries\n",
    "    for bbox, cat_id in zip(transformed['bboxes'], transformed['category_ids']):\n",
    "        new_annotations.append({\n",
    "            \"id\": new_annotation_id,\n",
    "            \"image_id\": new_image_id,\n",
    "            \"category_id\": cat_id,\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": 0,\n",
    "            \"area\": bbox[2] * bbox[3]\n",
    "        })\n",
    "        new_annotation_id += 1\n",
    "\n",
    "    new_image_id += 1\n",
    "\n",
    "# Create final annotation object\n",
    "augmented_coco = deepcopy(coco)\n",
    "augmented_coco['images'].extend(new_images)\n",
    "augmented_coco['annotations'].extend(new_annotations)\n",
    "\n",
    "# Save to new annotations file\n",
    "with open(aug_dataset_path / \"_annotations.coco.json\", 'w') as f:\n",
    "    json.dump(augmented_coco, f, indent=2)\n",
    "\n",
    "print(\"Data augmentation complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0072f",
   "metadata": {},
   "source": [
    "# 1.2 Pruebas Version 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bc7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db967be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported image type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m transform \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     31\u001b[0m     A\u001b[38;5;241m.\u001b[39mShiftScaleRotate(shift_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, scale_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, rotate_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m),\n\u001b[0;32m     32\u001b[0m ], bbox_params\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mBboxParams(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m'\u001b[39m, label_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Apply transformation\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m transformed \u001b[38;5;241m=\u001b[39m transform(image\u001b[38;5;241m=\u001b[39mimage, bboxes\u001b[38;5;241m=\u001b[39mbboxes, category_ids\u001b[38;5;241m=\u001b[39mcategory_ids)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Save new image\u001b[39;00m\n\u001b[0;32m     37\u001b[0m new_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\composition.py:493\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m need_to_run:\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m    496\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\composition.py:533\u001b[0m, in \u001b[0;36mCompose.preprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrict:\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(data)\n\u001b[1;32m--> 533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_processors(data)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_arrays(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\composition.py:560\u001b[0m, in \u001b[0;36mCompose._preprocess_processors\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    558\u001b[0m     processor\u001b[38;5;241m.\u001b[39mensure_data_valid(data)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 560\u001b[0m     processor\u001b[38;5;241m.\u001b[39mpreprocess(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\utils.py:144\u001b[0m, in \u001b[0;36mDataProcessor.preprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     shape \u001b[38;5;241m=\u001b[39m get_shape(data)\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fields) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys()):  \u001b[38;5;66;03m# Convert list of lists to numpy array if necessary\u001b[39;00m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[data_name], Sequence):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\utils.py:63\u001b[0m, in \u001b[0;36mget_shape\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m: depth, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: height, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: width}\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m---> 63\u001b[0m     height, width \u001b[38;5;241m=\u001b[39m get_image_shape(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: height, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: width}\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\core\\utils.py:31\u001b[0m, in \u001b[0;36mget_image_shape\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported image type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unsupported image type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths\n",
    "dataset_path = Path(\"datasets/unified_dataset\")\n",
    "aug_dataset_path = Path(\"datasets/unified_dataset_data_augmentation_v2\")\n",
    "aug_images_path = aug_dataset_path / \"images\"\n",
    "aug_images_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(dataset_path / \"_annotations.coco.json\", 'r') as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# Select a single image (first one)\n",
    "img_info = coco['images'][0]\n",
    "img_path = dataset_path / img_info['file_name']\n",
    "image = cv2.imread(str(img_path))\n",
    "\n",
    "# Get annotations for this image\n",
    "image_id = img_info['id']\n",
    "anns = [ann for ann in coco['annotations'] if ann['image_id'] == image_id]\n",
    "bboxes = [ann['bbox'] for ann in anns]\n",
    "category_ids = [ann['category_id'] for ann in anns]\n",
    "\n",
    "# Albumentations transform (tweak here)\n",
    "'''\n",
    "transform = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.04, scale_limit=0.05, rotate_limit=10, p=1.0),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),\n",
    "    A.MotionBlur(blur_limit=3, p=1.0)\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "'''\n",
    "transform = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=10, p=1.0),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "# Apply transformation\n",
    "transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "\n",
    "# Save new image\n",
    "new_file_name = f\"aug_{img_info['file_name']}\"\n",
    "cv2.imwrite(str(aug_images_path / new_file_name), transformed['image'])\n",
    "\n",
    "# Build new image + annotations\n",
    "new_image_id = max(img['id'] for img in coco['images']) + 1\n",
    "new_annotation_id = max(ann['id'] for ann in coco['annotations']) + 1\n",
    "\n",
    "aug_img = {\n",
    "    \"id\": new_image_id,\n",
    "    \"file_name\": f\"images/{new_file_name}\",\n",
    "    \"width\": img_info['width'],\n",
    "    \"height\": img_info['height']\n",
    "}\n",
    "\n",
    "aug_anns = []\n",
    "for bbox, cat_id in zip(transformed['bboxes'], transformed['category_ids']):\n",
    "    aug_anns.append({\n",
    "        \"id\": new_annotation_id,\n",
    "        \"image_id\": new_image_id,\n",
    "        \"category_id\": cat_id,\n",
    "        \"bbox\": bbox,\n",
    "        \"iscrowd\": 0,\n",
    "        \"area\": bbox[2] * bbox[3]\n",
    "    })\n",
    "    new_annotation_id += 1\n",
    "\n",
    "# Create new COCO structure with original + one augmented image\n",
    "augmented_coco = deepcopy(coco)\n",
    "augmented_coco['images'].append(aug_img)\n",
    "augmented_coco['annotations'].extend(aug_anns)\n",
    "\n",
    "# Save to new JSON\n",
    "with open(aug_dataset_path / \"_annotations.coco.json\", 'w') as f:\n",
    "    json.dump(augmented_coco, f, indent=2)\n",
    "\n",
    "print(f\"Augmented one image: {img_info['file_name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eedd444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4377dfea",
   "metadata": {},
   "source": [
    "### Version 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95bfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3345b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_subset_data_augmentation(\n",
    "    image_folder_path,\n",
    "    coco_json_path,\n",
    "    output_image_folder_path,\n",
    "    output_json_path,\n",
    "    num_augmentations\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies data augmentation to images based on COCO annotations and saves the augmented images and new annotations.\n",
    "\n",
    "    Parameters:\n",
    "        image_folder_path (str): Path to the original image folder.\n",
    "        coco_json_path (str): Path to the original COCO JSON annotations.\n",
    "        output_image_folder_path (str): Directory to save augmented images.\n",
    "        output_json_path (str): Path to save the new COCO JSON file.\n",
    "        num_augmentations (int): Number of augmentations to apply per image.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_image_folder_path, exist_ok=True)\n",
    "\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.9),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "        A.MotionBlur(blur_limit=3, p=0.3)\n",
    "    ], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "    new_image_id = max(img['id'] for img in coco['images']) + 1\n",
    "    new_annotation_id = max(ann['id'] for ann in coco['annotations']) + 1\n",
    "\n",
    "    image_id_to_anns = {}\n",
    "    for ann in coco['annotations']:\n",
    "        image_id_to_anns.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "    for img_info in tqdm(coco['images'], desc=\"Augmenting images\"):\n",
    "        img_path = os.path.join(image_folder_path, img_info['file_name'])\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        anns = image_id_to_anns.get(img_info['id'], [])\n",
    "        bboxes = [ann['bbox'] for ann in anns]\n",
    "        category_ids = [ann['category_id'] for ann in anns]\n",
    "\n",
    "        if not bboxes:\n",
    "            continue\n",
    "\n",
    "        for i in range(1, num_augmentations + 1):\n",
    "            transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "            aug_file_name = f\"{Path(img_info['file_name']).stem}_aug-{i}{Path(img_info['file_name']).suffix}\"\n",
    "            aug_path = os.path.join(output_image_folder_path, aug_file_name)\n",
    "\n",
    "            cv2.imwrite(aug_path, transformed['image'])\n",
    "\n",
    "            new_images.append({\n",
    "                \"id\": new_image_id,\n",
    "                \"file_name\": aug_file_name,\n",
    "                \"width\": img_info['width'],\n",
    "                \"height\": img_info['height']\n",
    "            })\n",
    "\n",
    "            for bbox, cat_id in zip(transformed['bboxes'], transformed['category_ids']):\n",
    "                new_annotations.append({\n",
    "                    \"id\": new_annotation_id,\n",
    "                    \"image_id\": new_image_id,\n",
    "                    \"category_id\": cat_id,\n",
    "                    \"bbox\": bbox,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"area\": bbox[2] * bbox[3]\n",
    "                })\n",
    "                new_annotation_id += 1\n",
    "\n",
    "            new_image_id += 1\n",
    "\n",
    "    augmented_coco = {\n",
    "        \"images\": new_images,\n",
    "        \"annotations\": new_annotations,\n",
    "        \"categories\": coco['categories']\n",
    "    }\n",
    "\n",
    "    # Create output folder for JSON if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n",
    "\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(augmented_coco, f, indent=2)\n",
    "\n",
    "    print(\"Data augmentation complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1068bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 665/665 [06:04<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_subset_data_augmentation(\n",
    "    image_folder_path='datasets/unified_dataset/images',\n",
    "    coco_json_path='datasets/unified_dataset/subsets/train.json',\n",
    "    output_image_folder_path='datasets/unified_dataset/train_augmented/images',\n",
    "    output_json_path='datasets/unified_dataset/train_augmented/train_augmented.json',\n",
    "    num_augmentations=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c0c8b",
   "metadata": {},
   "source": [
    "## Verificacion de BBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70dbc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7837856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coco_bboxes_to_images(image_dir, annotation_path, output_dir='output', max_images=None):\n",
    "    \"\"\"\n",
    "    Save images with bounding boxes drawn from COCO annotations.\n",
    "\n",
    "    Parameters:\n",
    "        image_dir (str): Directory containing the images.\n",
    "        annotation_path (str): Full path to the COCO annotation file.\n",
    "        output_dir (str): Directory to save output images with drawn bounding boxes.\n",
    "        max_images (int, optional): If provided, randomly selects up to this number of images (without repetition).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    coco = COCO(annotation_path)\n",
    "    image_ids = coco.getImgIds()\n",
    "\n",
    "    if max_images is not None and max_images < len(image_ids):\n",
    "        image_ids = random.sample(image_ids, max_images)\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        img_data = coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(image_dir, img_data['file_name'])\n",
    "        output_path = os.path.join(output_dir, img_data['file_name'])\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"[WARNING] Image file not found: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            draw.rectangle([x, y, x + w, y + h], outline='red', width=3)\n",
    "\n",
    "        image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "119c1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "save_coco_bboxes_to_images(\n",
    "    image_dir='datasets/unified_dataset/train_augmented/images',\n",
    "    annotation_path='datasets/unified_dataset/train_augmented/train_augmented.json',\n",
    "    output_dir='datasets/unified_dataset/train_augmented/images_bbox_test',\n",
    "    max_images=10\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
