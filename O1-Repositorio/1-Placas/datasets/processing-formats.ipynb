{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c043f2",
   "metadata": {},
   "source": [
    "# 1. Prueba - Data Augmentation 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d3f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1daeb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the directory path\n",
    "#image_dir = 'ANPR2.v1i.yolov8/train_del/images'\n",
    "image_dir = 'Peru Plate Numbers.v3i.yolov8/train_del/images'\n",
    "\n",
    "# Supported image extensions\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "# Get list of image file names\n",
    "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "# Write to CSV\n",
    "with open('image_files.csv', mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for filename in image_files:\n",
    "        writer.writerow([filename])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802621d1",
   "metadata": {},
   "source": [
    "# 2. Aplicar format COCO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d52e49",
   "metadata": {},
   "source": [
    "## 2.1 Limpiar JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb35627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbad508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coco_by_images(coco_path, image_dir, output_path):\n",
    "    with open(coco_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    valid_filenames = {f.name for f in Path(image_dir).glob(\"*\")}\n",
    "    image_id_map = {\n",
    "        img['id']: img for img in data['images']\n",
    "        if img['file_name'] in valid_filenames\n",
    "    }\n",
    "\n",
    "    data['images'] = list(image_id_map.values())\n",
    "    valid_ids = set(image_id_map.keys())\n",
    "    data['annotations'] = [\n",
    "        ann for ann in data['annotations'] if ann['image_id'] in valid_ids\n",
    "    ]\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved filtered annotations to {output_path}\")\n",
    "\n",
    "def check_duplicate_filenames(*dirs):\n",
    "    seen = {}\n",
    "    duplicates = []\n",
    "\n",
    "    for dir_path in dirs:\n",
    "        for img_file in Path(dir_path).glob(\"*\"):\n",
    "            fname = img_file.name\n",
    "            if fname in seen:\n",
    "                duplicates.append((fname, seen[fname], dir_path))\n",
    "            else:\n",
    "                seen[fname] = dir_path\n",
    "\n",
    "    if duplicates:\n",
    "        print(\"Duplicate image filenames found:\")\n",
    "        for fname, dir1, dir2 in duplicates:\n",
    "            print(f\"{fname} found in:\\n - {dir1}\\n - {dir2}\\n\")\n",
    "    else:\n",
    "        print(\"No duplicate image filenames found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ac885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered annotations to PPN_train_coco_annotations.coco.json\n",
      "Saved filtered annotations to ANPR2_train_coco_annotations.coco.json\n",
      "Duplicate image filenames found:\n",
      "_annotations.coco.json found in:\n",
      " - Peru Plate Numbers.v3i.coco/test\n",
      " - Peru Plate Numbers.v3i.coco/valid\n",
      "\n",
      "_annotations.coco.json found in:\n",
      " - Peru Plate Numbers.v3i.coco/test\n",
      " - ANPR2.v1i.coco/test\n",
      "\n",
      "_annotations.coco.json found in:\n",
      " - Peru Plate Numbers.v3i.coco/test\n",
      " - ANPR2.v1i.coco/valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir_1 = Path(\"Peru Plate Numbers.v3i.yolov8/train_filter_v7/images\")\n",
    "image_dir_2 = Path(\"ANPR2.v1i.yolov8/train_stage7_options/images\")\n",
    "coco_1_train = Path(\"Peru Plate Numbers.v3i.coco/train/_annotations.coco.json\")\n",
    "coco_2_train = Path(\"ANPR2.v1i.coco/train/_annotations.coco.json\")\n",
    "\n",
    "# Step 1 & 2\n",
    "filter_coco_by_images(coco_1_train, image_dir_1, \"PPN_train_coco_annotations.coco.json\")\n",
    "filter_coco_by_images(coco_2_train, image_dir_2, \"ANPR2_train_coco_annotations.coco.json\")\n",
    "\n",
    "# Step 3\n",
    "test_valid_dirs = [\n",
    "    \"Peru Plate Numbers.v3i.coco/test\",\n",
    "    \"Peru Plate Numbers.v3i.coco/valid\",\n",
    "    \"ANPR2.v1i.coco/test\",\n",
    "    \"ANPR2.v1i.coco/valid\"\n",
    "]\n",
    "check_duplicate_filenames(image_dir_1, image_dir_2, *test_valid_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ea0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered annotations to PPN_test_coco_annotations.coco.json\n",
      "Saved filtered annotations to ANPR2_valid_coco_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir_3 = Path(\"ANPR2.v1i.yolov8/test_v2/images\")\n",
    "image_dir_4 = Path(\"ANPR2.v1i.yolov8/valid_v2/images\")\n",
    "coco_3 = Path(\"Peru Plate Numbers.v3i.coco/test/_annotations.coco.json\")\n",
    "coco_4 = Path(\"ANPR2.v1i.coco/valid/_annotations.coco.json\")\n",
    "\n",
    "# Step 1 & 2\n",
    "filter_coco_by_images(coco_3, image_dir_3, \"PPN_test_coco_annotations.coco.json\")\n",
    "filter_coco_by_images(coco_4, image_dir_4, \"ANPR2_valid_coco_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9050e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_dir_3 = Path(\"ANPR2.v1i.yolov8/test_v2/images\")\n",
    "image_dir_4 = Path(\"ANPR2.v1i.yolov8/valid_v2/images\")\n",
    "coco_3 = Path(\"Peru Plate Numbers.v3i.coco/test/_annotations.coco.json\")\n",
    "coco_4 = Path(\"ANPR2.v1i.coco/valid/_annotations.coco.json\")\n",
    "\n",
    "# Step 1 & 2\n",
    "filter_coco_by_images(coco_3, image_dir_3, \"PPN_test_coco_annotations.coco.json\")\n",
    "filter_coco_by_images(coco_4, image_dir_4, \"ANPR2_valid_coco_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfddf2",
   "metadata": {},
   "source": [
    "## 2.2 Mostrar frecuencias de las categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ccddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def display_category_frequencies_with_ids(annotation_path):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    category_counts = Counter(ann['category_id'] for ann in data['annotations'])\n",
    "    category_names = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "    print(f\"Frequencies in {annotation_path}:\")\n",
    "    for cat_id, count in category_counts.items():\n",
    "        name = category_names.get(cat_id, f\"Unknown\")\n",
    "        print(f\"  ID {cat_id} - {name}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies in PPN_coco_annotations.coco.json:\n",
      "  ID 1 - Placa: 774\n",
      "  ID 2 - placa: 137\n",
      "\n",
      "Frequencies in ANPR2_coco_annotations.coco.json:\n",
      "  ID 1 - placa: 679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_category_frequencies_with_ids(\"PPN_train_coco_annotations.coco.json\")\n",
    "display_category_frequencies_with_ids(\"ANPR2_train_coco_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c3a23",
   "metadata": {},
   "source": [
    "## 2.3 Uniformizar \"category\"\n",
    "{\"id\": 0, \"name\": \"plate\", \"supercategory\": \"none\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa2cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unified category annotations to PPN_fixed_train_coco_annotations.coco.json\n",
      "Saved unified category annotations to ANPR2_fixed_train_coco_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def unify_category(annotation_path, output_path):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Replace categories with a single one\n",
    "    data['categories'] = [{\"id\": 0, \"name\": \"plate\", \"supercategory\": \"none\"}]\n",
    "\n",
    "    # Set all annotations to category_id 0\n",
    "    for ann in data['annotations']:\n",
    "        ann['category_id'] = 0\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved unified category annotations to {output_path}\")\n",
    "\n",
    "# Process both files\n",
    "unify_category(\"PPN_train_coco_annotations.coco.json\", \"PPN_fixed_train_coco_annotations.coco.json\")\n",
    "unify_category(\"ANPR2_train_coco_annotations.coco.json\", \"ANPR2_fixed_train_coco_annotations.coco.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unified category annotations to ANPR2_fixed_test_coco_annotations.coco.json\n",
      "Saved unified category annotations to ANPR2_fixed_valid_coco_annotations.coco.json\n",
      "Saved unified category annotations to PPN_fixed_test_coco_annotations.coco.json\n",
      "Saved unified category annotations to PPN_fixed_valid_coco_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "#unify_category(\"ANPR2.v1i.coco/test/_annotations.coco.json\", \"ANPR2_fixed_test_coco_annotations.coco.json\")\n",
    "#unify_category(\"ANPR2.v1i.coco/valid/_annotations.coco.json\", \"ANPR2_fixed_valid_coco_annotations.coco.json\")\n",
    "#unify_category(\"Peru Plate Numbers.v3i.coco/test/_annotations.coco.json\", \"PPN_fixed_test_coco_annotations.coco.json\")\n",
    "#unify_category(\"Peru Plate Numbers.v3i.coco/valid/_annotations.coco.json\", \"PPN_fixed_valid_coco_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0c127",
   "metadata": {},
   "source": [
    "## 2.4 Renombrar nombres de los archivos de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4feeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_images_and_update_coco(image_dir, coco_json_path, new_json_name):\n",
    "    image_dir = Path(image_dir)\n",
    "    coco_json_path = Path(coco_json_path)\n",
    "    new_json_path = coco_json_path.parent / new_json_name\n",
    "\n",
    "    # Load original JSON\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Build mapping from old name to new name using regex\n",
    "    name_map = {}\n",
    "    for img_file in image_dir.glob(\"*.*\"):\n",
    "        old_name = img_file.name\n",
    "        base, ext = os.path.splitext(old_name)\n",
    "\n",
    "        match = re.match(r\"(.+?)_?(?:jpg|jpeg|png)?\\.rf\\.[^.]+\", base)\n",
    "        if not match:\n",
    "            continue  # skip if pattern doesn't match\n",
    "\n",
    "        new_stem = match.group(1)\n",
    "        new_name = f\"{new_stem}{ext}\"\n",
    "        name_map[old_name] = new_name\n",
    "\n",
    "        # Rename file\n",
    "        img_file.rename(image_dir / new_name)\n",
    "\n",
    "    # Update JSON\n",
    "    updated_coco = coco.copy()\n",
    "    for img in updated_coco['images']:\n",
    "        old_name = Path(img['file_name']).name\n",
    "        if old_name in name_map:\n",
    "            img['file_name'] = name_map[old_name]\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(new_json_path, 'w') as f:\n",
    "        json.dump(updated_coco, f, indent=2)\n",
    "\n",
    "    print(f\"Renamed {len(name_map)} images and saved updated JSON to {new_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f126088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 437 images and saved updated JSON to ANPR2_renamed_train_coco_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "rename_images_and_update_coco(\n",
    "    image_dir=\"ANPR2.v1i.yolov8/train_stage8_options/images\",\n",
    "    coco_json_path=\"ANPR2_fixed_train_coco_annotations.coco.json\",\n",
    "    new_json_name=\"ANPR2_renamed_train_coco_annotations.coco.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0980a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 450 images and saved updated JSON to PPN_renamed_train_coco_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "rename_images_and_update_coco(\n",
    "    image_dir=\"Peru Plate Numbers.v3i.yolov8/train_filter_v8/images\",\n",
    "    coco_json_path=\"PPN_fixed_train_coco_annotations.coco.json\",\n",
    "    new_json_name=\"PPN_renamed_train_coco_annotations.coco.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a70042",
   "metadata": {},
   "source": [
    "## 2.5 Ver repetidos en train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e56afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repeated_filenames(json_path_1, json_path_2, output_txt_path):\n",
    "    # Load both JSONs\n",
    "    with open(json_path_1, 'r') as f1, open(json_path_2, 'r') as f2:\n",
    "        coco1 = json.load(f1)\n",
    "        coco2 = json.load(f2)\n",
    "\n",
    "    # Extract image filenames\n",
    "    filenames1 = {Path(img['file_name']).name for img in coco1['images']}\n",
    "    filenames2 = {Path(img['file_name']).name for img in coco2['images']}\n",
    "\n",
    "    # Find duplicates\n",
    "    repeated = sorted(filenames1 & filenames2)\n",
    "\n",
    "    # Write results to output file\n",
    "    with open(output_txt_path, 'w') as out:\n",
    "        for name in repeated:\n",
    "            out.write(name + '\\n')\n",
    "\n",
    "    print(f\"Found {len(repeated)} repeated filenames. Saved to {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c783ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 223 repeated filenames. Saved to coco_repeated_filenames.txt\n"
     ]
    }
   ],
   "source": [
    "find_repeated_filenames(\n",
    "    json_path_1=\"ANPR2_renamed_train_coco_annotations.coco.json\",\n",
    "    json_path_2=\"PPN_renamed_train_coco_annotations.coco.json\",\n",
    "    output_txt_path=\"coco_repeated_filenames.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bbed2e",
   "metadata": {},
   "source": [
    "## 2.6 Unificar COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbde4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as unified_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_and_offset(json_path, image_id_offset, annotation_id_offset):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Offset image and annotation IDs\n",
    "    images = data['images']\n",
    "    annotations = data['annotations']\n",
    "\n",
    "    for img in images:\n",
    "        img['id'] += image_id_offset\n",
    "\n",
    "    for ann in annotations:\n",
    "        ann['image_id'] += image_id_offset\n",
    "        ann['id'] += annotation_id_offset\n",
    "\n",
    "    return images, annotations\n",
    "\n",
    "# List of files to merge\n",
    "files = [\n",
    "    \"PPN_fixed_train_coco_annotations.coco.json\",\n",
    "    \"PPN_fixed_test_coco_annotations.coco.json\",\n",
    "    \"PPN_fixed_valid_coco_annotations.coco.json\",\n",
    "    \"ANPR2_fixed_train_coco_annotations.coco.json\",\n",
    "    \"ANPR2_fixed_test_coco_annotations.coco.json\",\n",
    "    \"ANPR2_fixed_valid_coco_annotations.coco.json\",\n",
    "]\n",
    "\n",
    "unified = {\n",
    "    \"info\": {\"description\": \"Unified dataset\"},\n",
    "    \"licenses\": [],\n",
    "    \"categories\": [{\"id\": 0, \"name\": \"plate\", \"supercategory\": \"none\"}],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "image_id_offset = 0\n",
    "annotation_id_offset = 0\n",
    "\n",
    "for path in files:\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images, annotations = load_and_offset(path, image_id_offset, annotation_id_offset)\n",
    "    unified[\"images\"].extend(images)\n",
    "    unified[\"annotations\"].extend(annotations)\n",
    "\n",
    "    # Update offsets\n",
    "    image_id_offset += max(img['id'] for img in images) + 1\n",
    "    annotation_id_offset += max(ann['id'] for ann in annotations) + 1\n",
    "\n",
    "# Save unified file\n",
    "with open(\"unified_annotations.coco.json\", \"w\") as f:\n",
    "    json.dump(unified, f, indent=2)\n",
    "\n",
    "print(\"Saved as unified_annotations.coco.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def print_bbox_count_per_image(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    bbox_counts = defaultdict(int)\n",
    "    for ann in data['annotations']:\n",
    "        bbox_counts[ann['image_id']] += 1\n",
    "\n",
    "    print(f\"BBox counts for each image in {json_path}:\")\n",
    "    for image_id, count in bbox_counts.items():\n",
    "        print(f\"  Image ID {image_id}: {count} bbox\")\n",
    "\n",
    "# Example usage\n",
    "print_bbox_count_per_image(\"unified_annotations.coco.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5dd0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in 'unified_dataset': 1238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_in_folder(folder_path):\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    image_files = [\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if os.path.splitext(f)[1].lower() in image_extensions\n",
    "    ]\n",
    "    print(f\"Total images in '{folder_path}': {len(image_files)}\")\n",
    "\n",
    "# Example usage\n",
    "count_images_in_folder(\"unified_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943d712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
